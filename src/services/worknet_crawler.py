from sqlalchemy.orm import Session
from database import User, CompanyInterest
import config
import mysql.connector
import requests
import xml.etree.ElementTree as ET
import json
import re
from dotenv import load_dotenv



# ==========================
#  ë¬¸ìì—´ ì •ê·œí™” (ê¸°ì—…ëª… ë¹„êµìš©)
# ==========================
def _normalize(s: str) -> str:
    """ê¸°ì—…ëª…/ë³„ì¹­ì„ ë‹¨ìˆœí™”í•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ì •ê·œí™”"""
    if not s:
        return ""
    s = re.sub(r"\(ì£¼\)", "", s)         # '(ì£¼)' ì œê±°
    s = re.sub(r"[\sÂ·â€¢\-_/]", "", s)     # ê³µë°± ë° íŠ¹ìˆ˜êµ¬ë¶„ì ì œê±°
    s = re.sub(r"[^\wê°€-í£]", "", s)     # í•œê¸€/ì˜ë¬¸/ìˆ«ì ì™¸ ì œê±°
    return s.lower()

# ==========================
#  ê´€ì‹¬ ê¸°ì—… ì„¸íŠ¸ êµ¬ì¶•
# ==========================
def build_interest_set(companies, aliases):
    """DBì—ì„œ ê°€ì ¸ì˜¨ ê¸°ì—…ëª… + ë³„ì¹­ì„ ì •ê·œí™”í•˜ì—¬ Setìœ¼ë¡œ ë§Œë“¦"""
    norm_set = set()
    for c in companies:
        norm_set.add(_normalize(c))
    for a in aliases:
        if a:
            norm_set.add(_normalize(a))
    return norm_set

# ==========================
#  ê´€ì‹¬ ê¸°ì—… ë§¤ì¹­ í•¨ìˆ˜
# ==========================
def is_interest_company(company_name: str, interest_norm_set) -> bool:
    """ì±„ìš©ê³µê³  ê¸°ì—…ëª…ì´ ê´€ì‹¬ê¸°ì—… ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ”ì§€ ê²€ì‚¬"""
    n = _normalize(company_name)
    if not n:
        return False
    # â‘  ì •í™• ì¼ì¹˜
    if n in interest_norm_set:
        return True
    # â‘¡ ë¶€ë¶„ í¬í•¨ (ì•ë’¤ ë¬¸ìì—´ í¬í•¨)
    for target in interest_norm_set:
        if target in n or n in target:
            return True
    return False


# ==========================
#  DBì—ì„œ ê´€ì‹¬ ê¸°ì—… ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================
def fetch_companies_from_db(db: Session, user_id: int) -> (list, list):
    """DBì—ì„œ íŠ¹ì • ì‚¬ìš©ìì˜ ê´€ì‹¬ ê¸°ì—… ëª©ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    print(f"ğŸ” DBì—ì„œ ì‚¬ìš©ì(id={user_id})ì˜ ê´€ì‹¬ ê¸°ì—… ë¶ˆëŸ¬ì˜¤ê¸°")

    # user_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ ì‚¬ìš©ìì˜ ê´€ì‹¬ ê¸°ì—…ë§Œ ì¡°íšŒ
    interests = db.query(CompanyInterest).filter(CompanyInterest.user_id == user_id).all()
    
    if not interests:
        print(f" ì‚¬ìš©ì(id={user_id})ì—ê²Œ ë“±ë¡ëœ ê´€ì‹¬ ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return [], []

    companies = [item.company_name for item in interests]
    
    print(f"âœ… ê´€ì‹¬ ê¸°ì—… {len(companies)}ê°œ ë¶ˆëŸ¬ì˜´: {companies}")
    return companies, []

# ==========================
#  API í˜¸ì¶œ ë° ê´€ì‹¬ê¸°ì—… í•„í„°ë§
# ==========================
def fetch_and_filter_jobs(companies, aliases):
    if not companies:
        print(" ê´€ì‹¬ ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    url = "https://www.work24.go.kr/cm/openApi/call/wk/callOpenApiSvcInfo210L21.do"
    all_raw_jobs = []
    interest_norm_set = build_interest_set(companies, aliases)

    print("\nğŸ“¦ API ì±„ìš©ê³µê³  ìˆ˜ì§‘ ì‹œì‘\n")

    # í˜ì´ì§€ ë£¨í”„ (ìµœëŒ€ 10í˜ì´ì§€ë§Œ ì˜ˆì‹œë¡œ ì„¤ì •)
    for page in range(1, 11):
        params = {
            "authKey": config.WORKNET_API_KEY,   
            "callTp": "L",
            "returnType": "XML",
            "startPage": str(page),
            "display": "100"
        }

        try:
            response = requests.get(url, params=params)
            if response.status_code != 200:
                print(f" API ìš”ì²­ ì‹¤íŒ¨ (í˜ì´ì§€ {page})")
                break

            root = ET.fromstring(response.content)

            for job_item in root.findall(".//dhsOpenEmpInfo"):
                company_name = job_item.findtext("empBusiNm") or ""

                # ê´€ì‹¬ê¸°ì—…ë§Œ í•„í„°ë§
                if not is_interest_company(company_name, interest_norm_set):
                    continue
                
                print(f" ë§¤ì¹­ëœ ê¸°ì—…: {company_name}")  # ë¡œê·¸ ì¶œë ¥ í™•ì¸ìš©

                job_data = {  ## ì›Œí¬ë„· ì¶œë ¥ì˜ˆì‹œì— ìˆëŠ”  íŒŒë¼ë¯¸í„°ë“¤
                    "company_name": company_name,
                    "job_title": job_item.findtext("empWantedTitle"),
                    "employment_type": job_item.findtext("empWantedTypeNm"),
                    "start_date": job_item.findtext("empWantedStdt"),
                    "end_date": job_item.findtext("empWantedEndt"),
                    "company_type": job_item.findtext("coClcdNm"),
                    "company_logo": job_item.findtext("regLogImgNm"),
                    "apply_link": job_item.findtext("empWantedHomepgDetail"),
                }
                all_raw_jobs.append(job_data)

        except Exception as e:
            print(f" API ì˜¤ë¥˜ (í˜ì´ì§€ {page}): {e}")
            continue

    print(f"\n ê´€ì‹¬ê¸°ì—… ê³µê³  ìˆ˜ì§‘ ê²°ê³¼: {len(all_raw_jobs)}ê±´")
    return all_raw_jobs



def fetch_companies_from_db(db: Session, user_id: int) -> (list, list):
    """DBì—ì„œ íŠ¹ì • ì‚¬ìš©ìì˜ ê´€ì‹¬ ê¸°ì—… ëª©ë¡ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    print(f"ğŸ” DBì—ì„œ ì‚¬ìš©ì(id={user_id})ì˜ ê´€ì‹¬ ê¸°ì—… ë¶ˆëŸ¬ì˜¤ê¸°")
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        print(f"âŒ ì‚¬ìš©ì(id={user_id})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return [], []
        
    interests = db.query(CompanyInterest).filter(CompanyInterest.user_id == user_id).all()
    companies = [item.company_name for item in interests]
    # ë³„ì¹­(alias) ê¸°ëŠ¥ì€ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì´ë²ˆ ë¦¬íŒ©í† ë§ì—ì„œëŠ” ì œì™¸
    print(f"âœ… ê´€ì‹¬ ê¸°ì—… {len(companies)}ê°œ ë¶ˆëŸ¬ì˜´: {companies}")
    return companies, []


def run_worknet_crawling(db: Session, user_id: int) -> list:
    """í•œ ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•œ ì›Œí¬ë„· í¬ë¡¤ë§ ì „ì²´ ê³¼ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    companies, aliases = fetch_companies_from_db(db, user_id)
    if not companies:
        return []
    raw_jobs = fetch_and_filter_jobs(companies, aliases)
    return raw_jobs

