import mysql.connector
import requests
import xml.etree.ElementTree as ET
import json
import re
from dotenv import load_dotenv

# ==========================
#  ğŸ”‘ Worknet API KEY ì§ì ‘ ì…ë ¥
# ==========================

# WORKNET_API_KEY = "WORKNET_API_KEY"   # â† ì§ì ‘ í‚¤ ì…ë ¥
load_dotenv()

# ==========================
#  ë¬¸ìì—´ ì •ê·œí™” (ê¸°ì—…ëª… ë¹„êµìš©)
# ==========================
def _normalize(s: str) -> str:
    """ê¸°ì—…ëª…/ë³„ì¹­ì„ ë‹¨ìˆœí™”í•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ì •ê·œí™”"""
    if not s:
        return ""
    s = re.sub(r"\(ì£¼\)", "", s)         # '(ì£¼)' ì œê±°
    s = re.sub(r"[\sÂ·â€¢\-_/]", "", s)     # ê³µë°± ë° íŠ¹ìˆ˜êµ¬ë¶„ì ì œê±°
    s = re.sub(r"[^\wê°€-í£]", "", s)     # í•œê¸€/ì˜ë¬¸/ìˆ«ì ì™¸ ì œê±°
    return s.lower()

# ==========================
#  ê´€ì‹¬ ê¸°ì—… ì„¸íŠ¸ êµ¬ì¶•
# ==========================
def build_interest_set(companies, aliases):
    """DBì—ì„œ ê°€ì ¸ì˜¨ ê¸°ì—…ëª… + ë³„ì¹­ì„ ì •ê·œí™”í•˜ì—¬ Setìœ¼ë¡œ ë§Œë“¦"""
    norm_set = set()
    for c in companies:
        norm_set.add(_normalize(c))
    for a in aliases:
        if a:
            norm_set.add(_normalize(a))
    return norm_set

# ==========================
#  ê´€ì‹¬ ê¸°ì—… ë§¤ì¹­ í•¨ìˆ˜
# ==========================
def is_interest_company(company_name: str, interest_norm_set) -> bool:
    """ì±„ìš©ê³µê³  ê¸°ì—…ëª…ì´ ê´€ì‹¬ê¸°ì—… ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ”ì§€ ê²€ì‚¬"""
    n = _normalize(company_name)
    if not n:
        return False
    # â‘  ì •í™• ì¼ì¹˜
    if n in interest_norm_set:
        return True
    # â‘¡ ë¶€ë¶„ í¬í•¨ (ì•ë’¤ ë¬¸ìì—´ í¬í•¨)
    for target in interest_norm_set:
        if target in n or n in target:
            return True
    return False

# ==========================
#  DB ì„¤ì • -> ì¼ë‹¨ ì¶œë ¥ ê²€ì‚¬ìœ„í•´ ê°œì¸ìš© dbì— ì €ì¥
# ==========================
db_config = {
    'host': 'localhost',
    'user': 'root',    ## DB ì‚¬ìš©ì ê³„ì • (MySQL ì„¤ì¹˜ ì‹œ ë§Œë“  ê³„ì •, ê¸°ë³¸ì€ 'root')
    'password': 'dldudwns01~',  ## í•´ë‹¹ ê³„ì •ì˜ ë¹„ë°€ë²ˆí˜¸
    'database': 'mysql' ## ì ‘ì†í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ (ì—¬ê¸°ì„œëŠ” 'mysql')
}

# ==========================
#  DBì—ì„œ ê´€ì‹¬ ê¸°ì—… ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================
def fetch_companies_from_db():
    print("\nğŸ” DBì—ì„œ ê´€ì‹¬ ê¸°ì—… ë¶ˆëŸ¬ì˜¤ê¸°")
    companies, aliases = [], []
    try:
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor()
        cursor.execute("SELECT name, alias FROM companies")
        rows = cursor.fetchall()

        companies = [row[0] for row in rows if row[0]]
        aliases = [row[1] for row in rows if len(row) > 1 and row[1]]

        print(f"âœ… DB ê¸°ì—…ëª… {len(companies)}ê°œ, ë³„ì¹­ {len([a for a in aliases if a])}ê°œ ë¶ˆëŸ¬ì˜´")
    except mysql.connector.Error as err:
        print(f"âŒ DB ì˜¤ë¥˜: {err}")
    finally:
        if 'conn' in locals() and conn.is_connected():
            cursor.close()
            conn.close()
    return companies, aliases

# ==========================
#  API í˜¸ì¶œ ë° ê´€ì‹¬ê¸°ì—… í•„í„°ë§
# ==========================
def fetch_and_filter_jobs(companies, aliases):
    if not companies:
        print("âŒ ê´€ì‹¬ ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []

    url = "https://www.work24.go.kr/cm/openApi/call/wk/callOpenApiSvcInfo210L21.do"
    all_raw_jobs = []
    interest_norm_set = build_interest_set(companies, aliases)

    print("\nğŸ“¦ API ì±„ìš©ê³µê³  ìˆ˜ì§‘ ì‹œì‘\n")

    # í˜ì´ì§€ ë£¨í”„ (ìµœëŒ€ 10í˜ì´ì§€ë§Œ ì˜ˆì‹œë¡œ ì„¤ì •)
    for page in range(1, 11):
        params = {
            "authKey": WORKNET_API_KEY,   
            "callTp": "L",
            "returnType": "XML",
            "startPage": str(page),
            "display": "100"
        }

        try:
            response = requests.get(url, params=params)
            if response.status_code != 200:
                print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨ (í˜ì´ì§€ {page})")
                break

            root = ET.fromstring(response.content)

            for job_item in root.findall(".//dhsOpenEmpInfo"):
                company_name = job_item.findtext("empBusiNm") or ""

                # ê´€ì‹¬ê¸°ì—…ë§Œ í•„í„°ë§
                if not is_interest_company(company_name, interest_norm_set):
                    continue
                
                print(f"ğŸ¯ ë§¤ì¹­ëœ ê¸°ì—…: {company_name}")  # ë¡œê·¸ ì¶œë ¥ í™•ì¸ìš©

                job_data = {  ## ì›Œí¬ë„· ì¶œë ¥ì˜ˆì‹œì— ìˆëŠ”  íŒŒë¼ë¯¸í„°ë“¤
                    "company_name": company_name,
                    "job_title": job_item.findtext("empWantedTitle"),
                    "employment_type": job_item.findtext("empWantedTypeNm"),
                    "start_date": job_item.findtext("empWantedStdt"),
                    "end_date": job_item.findtext("empWantedEndt"),
                    "company_type": job_item.findtext("coClcdNm"),
                    "company_logo": job_item.findtext("regLogImgNm"),
                    "apply_link": job_item.findtext("empWantedHomepgDetail"),
                }
                all_raw_jobs.append(job_data)

        except Exception as e:
            print(f"âŒ API ì˜¤ë¥˜ (í˜ì´ì§€ {page}): {e}")
            continue

    print(f"\nğŸ“Š ê´€ì‹¬ê¸°ì—… ê³µê³  ìˆ˜ì§‘ ê²°ê³¼: {len(all_raw_jobs)}ê±´")
    return all_raw_jobs

# ==========================
#  JSON ì €ì¥
# ==========================
def save_jobs_to_json(data, filename="raw_job_data.json"):
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"âœ… '{filename}' ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ JSON ì €ì¥ ì˜¤ë¥˜: {e}")

# ==========================
#  ë©”ì¸ ì‹¤í–‰
# ==========================
def main():
    companies, aliases = fetch_companies_from_db()
    raw_jobs = fetch_and_filter_jobs(companies, aliases)

    if raw_jobs:
        save_jobs_to_json(raw_jobs)
        print("\nğŸ‰ ì±„ìš©ê³µê³  ìˆ˜ì§‘ ì™„ë£Œ")
    else:
        print("\nğŸ’¡ ê´€ì‹¬ ê¸°ì—… ê³µê³  ì—†ìŒ")

if __name__ == "__main__":
    main()
